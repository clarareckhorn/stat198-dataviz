Y_1 = df$Y_1,
Y_0 = df$Y_0
)
my_d_i <- as.numeric(df$Y_1 - df$Y_0)
# Step 6: Compute observed ATE
my_ATE_obs <- mean(df$Y[df$Z == 1]) - mean(df$Y[df$Z == 0])
# Step 7: Generate randomization distribution and p-value
stats <- rand_stats(schedule = my_null_sched, d_i = my_d_i)
# Two-sided p-value
p_value <- mean(abs(stats) >= abs(my_ATE_obs))
p_value
my_null_sched <- data.frame(
Z = df$Z,
Y_1 = df$Y_1,
Y_0 = df$Y_0
)
my_d_i <- as.numeric(df$Y_1 - df$Y_0)
# Step 6: Compute observed ATE
my_ATE_obs <- mean(df$Y[df$Z == 1]) - mean(df$Y[df$Z == 0])
# Step 7: Generate randomization distribution and p-value
stats <- rand_stats(schedule = my_null_sched, d_i = my_d_i)
p_value <- mean(abs(stats) >= abs(my_ATE_obs))
p_value
my_null_sched <- data.frame(
Z = df$Z,
Y_1 = df$Y_1,
Y_0 = df$Y_0
)
my_d_i <- as.numeric(df$Y_1 - df$Y_0)
# Step 6: Compute observed ATE
my_ATE_obs <- mean(df$Y[df$Z == 1]) - mean(df$Y[df$Z == 0])
my_ATE_obs
# Step 7: Generate randomization distribution and p-value
stats <- rand_stats(schedule = my_null_sched, d_i = my_d_i)
p_value <- mean(abs(stats) >= abs(my_ATE_obs))
p_value
my_null_sched <- data.frame(
Z = df$Z,
Y_1 = df$Y_1,
Y_0 = df$Y_0
)
my_d_i <- df$Y  # just use observed outcomes
stats <- rand_stats(schedule = my_null_sched, d_i = my_d_i)
my_ATE_obs <- mean(df$Y[df$Z == 1]) - mean(df$Y[df$Z == 0])
p_value <- mean(abs(stats) >= abs(my_ATE_obs))
p_value  # now you will see a number < 1
p1 <- sum(df$Y[df$Z == 1])
p2 <- sum(df$Y[df$Z == 0])
# Count total in each group
n1 <- sum(df$Z == 1)
n2 <- sum(df$Z == 0)
# Conduct two-sample z-test (prop.test)
z_test <- prop.test(c(p1, p2), c(n1, n2), correct = FALSE)
# View p-value
z_test$p.value
library(tidyverse)
anchor_mini_sched <- tibble(Y_0 = c(15, 15, 19, 2, 10, 8),
Y_1 = c(31, 22, 45, 20, 20, 15))
anchor_mini_sched
assignments <- combn(1:6, 3, simplify = FALSE)
ate <- map_dbl(assignments, function(treat_ids) {
treated <- data %>% filter(id %in% treat_ids)
control <- data %>% filter(!id %in% treat_ids)
mean(treated$Y1) - mean(control$Y0)
})
assignments <- combn(1:6, 3, simplify = FALSE)
assignments <- combn(1:6, 3, simplify = FALSE)
# compute ATE for each assignment
ate <- map_dbl(assignments, function(treat_ids) {
treated <- df %>% filter(id %in% treat_ids)
control <- df %>% filter(!id %in% treat_ids)
mean(treated$Y1) - mean(control$Y0)
})
library(tidyverse)
library(tidyr)
anchor_mini_sched <- tibble(Y_0 = c(15, 15, 19, 2, 10, 8),
Y_1 = c(31, 22, 45, 20, 20, 15))
anchor_mini_sched
assignments <- combn(1:6, 3, simplify = FALSE)
assignments <- combn(1:6, 3, simplify = FALSE)
# compute ATE for each assignment
ate <- map_dbl(assignments, function(treat_ids) {
treated <- df %>% filter(id %in% treat_ids)
control <- df %>% filter(!id %in% treat_ids)
mean(treated$Y1) - mean(control$Y0)
})
library(tidyverse)
df <- tibble(
id = 1:6,
Y0 = c(15, 15, 19, 2, 10, 8),
Y1 = c(31, 22, 45, 20, 20, 15)
)
assignments <- combn(1:6, 3, simplify = FALSE)
ate <- map_dbl(assignments, function(treat_ids) {
treated <- df %>% filter(id %in% treat_ids)
control <- df %>% filter(!id %in% treat_ids)
mean(treated$Y1) - mean(control$Y0)
})
dist <- tibble(ATE = ate) %>%
count(ATE) %>%
mutate(probability = n / length(assignments))
dist
Y0 <- c(15, 15, 19, 2, 10, 8)
Y1 <- c(31, 22, 45, 20, 20, 15)
assignments <- combn(1:6, 3)
ate <- apply(assignments, 2, function(treat_ids) {
control_ids <- setdiff(1:6, treat_ids)
mean(Y1[treat_ids]) - mean(Y0[control_ids])
})
dist <- table(ate) / length(ate)
dist
dist <- table(ate) / length(ate)
ate_vals <- as.numeric(names(dist))
probs <- as.numeric(dist)
E_ate <- sum(ate_vals * probs)
E_ate
Var_ate <- sum((ate_vals - E_ate)^2 * probs)
Var_ate
library(tidyverse)
anchoring <- read.csv("https://stat158.berkeley.edu/spring-2026/data/anchoring/anchoring.csv")
library(tidyverse)
anchoring <- read.csv("https://stat158.berkeley.edu/spring-2026/data/anchoring/anchoring.csv")
head(anchoring)
df <- tibble(
X = c(11,11,73,73,11,73),
Y = c(16,5,20,40,73,70)
)
# Observed difference in means: mean(Y | X=73) - mean(Y | X=11)
obs_stat <- mean(df$Y[df$X==73]) - mean(df$Y[df$X==11])
obs_stat
set.seed(123)  # for reproducibility
rand_stats <- function(Y, X, n_sims=1000) {
replicate(n_sims, {
perm_X <- sample(X)  # shuffle assignments
mean(Y[perm_X==73]) - mean(Y[perm_X==11])
})
}
null_stats <- rand_stats(df$Y, df$X, n_sims=1000)
p_val <- mean(abs(null_stats) >= abs(obs_stat))
p_val
hist(null_stats, breaks=20, main="Null Distribution of Difference in Means",
xlab="Difference in Means (X=73 - X=11)", col="blue", border="white")
abline(v=obs_stat, col="pink", lwd=2)  # observed statistic
data_location <- "datasets"
df <- read.csv(file.path(data_location, "spotify_songs.csv"))
data_location <- "datasets"
#https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv
df <- read_csv("https://stat158.berkeley.edu/spring-2026/data/framing/framing.csv")
#df <- read.csv(file.path(data_location, "spotify_songs.csv"))
# run analysis
xx <- df[,c(4,12,13,14,15,16,17,18,19,20,21,22,23)]; xxx =df[,4]
data_location <- "datasets"
#https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv
df <- read_csv("https://stat158.berkeley.edu/spring-2026/data/framing/framing.csv")
#df <- read.csv(file.path(data_location, "spotify_songs.csv"))
# run analysis
xx <- df[,c(4,12,13,14,15,16,17,18,19,20,21,22,23)]; xxx =df[,4]
spotify <- read_csv("https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv")
# Select numeric audio features (excluding popularity)
features <- spotify %>%
select(where(is.numeric)) %>%
select(-popularity)
names(spotify)
spotify <- read_csv("https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv")
spotify <- spotify %>%
rename(popularity = track_popularity)
# Select numeric audio features (excluding popularity)
features <- spotify %>%
select(where(is.numeric)) %>%
select(-popularity)
# Compute correlations with popularity
correlations <- sapply(features, function(x) {
cor(spotify$popularity, x, use = "complete.obs")
})
# Put results into a data frame
results <- data.frame(
feature = names(correlations),
correlation = correlations
)
# Order by strongest positive relationship
results <- results %>%
arrange(desc(correlation))
print(results)
# Print most positively associated feature
best_feature <- results$feature[1]
cat("The feature most associated with popularity is:", best_feature)
generate_X <- function(N, rho) {
x1 <- rnorm(N, mean = 0, sd = 1)
x2 <- rnorm(N, mean = 0, sd = 1)
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
X <- cbind(1, z1, z2)  # include intercept
return(X)
}
# N equals number of observations
generate_X <- function(N, rho) {
x1 <- rnorm(N, mean = 0, sd = 1)
x2 <- rnorm(N, mean = 0, sd = 1)
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
X <- cbind(1, z1, z2)  # include intercept
return(X)
}
#function to generate yn and en
generate_y <- function(X, sigma, beta) {
N <- nrow(X)
epsilon <- rnorm(N, mean = 0, sd = sigma)
y <- X %*% beta + epsilon
return(list(y = as.vector(y), epsilon = epsilon))
}
#computes OLS estimator B
X <- cbind(1, x1, x2)
# N equals number of observations
generate_X <- function(N, rho) {
x1 <- rnorm(N, mean = 0, sd = 1)
x2 <- rnorm(N, mean = 0, sd = 1)
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
X <- cbind(1, z1, z2)  # include intercept
return(X)
}
#function to generate yn and en
generate_y <- function(X, sigma, beta) {
N <- nrow(X)
epsilon <- rnorm(N, mean = 0, sd = sigma)
y <- X %*% beta + epsilon
return(list(y = as.vector(y), epsilon = epsilon))
}
#computes OLS estimator B
X <- cbind(1, x1, x2)
#computes OLS estimator B
N <- 100
# Generate regressors
x1 <- rnorm(N, mean = 0, sd = 1)
x2 <- rnorm(N, mean = 0, sd = 1)
# True beta
beta <- c(1, 2, 3)
# Generate outcome
epsilon <- rnorm(N, mean = 0, sd = 1)
y <- beta[1] + beta[2]*x1 + beta[3]*x2 + epsilon
# Construct X and Y
X <- cbind(1, x1, x2)
Y <- as.matrix(y)
# OLS function
ols_estimator <- function(X, Y) {
solve(t(X) %*% X) %*% t(X) %*% Y
}
beta_hat <- ols_estimator(X, Y)
beta_hat
lm_fit <- lm(y ~ x1 + x2)
# Extract estimated coefficients
beta_lm <- coef(lm_fit)
beta_lm
as.vector(beta_hat)
beta_lm
generate_Z <- function(X, rho) {
x1 <- X[, 2]
x2 <- X[, 3]
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
Z <- cbind(1, z1, z2)
return(Z)
}
check_rho <- function(N, rho) {
x1 <- rnorm(N)
x2 <- rnorm(N)
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
cat("rho =", rho, "\n")
cat("Var(z1):", var(z1), "\n")
cat("Var(z2):", var(z2), "\n")
cat("Cov(z1,z2):", cov(z1, z2), "\n")
cat("Cor(z1,z2):", cor(z1, z2), "\n\n")
}
check_rho <- function(N, rho) {
x1 <- rnorm(N)
x2 <- rnorm(N)
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
cat("rho =", rho, "\n")
cat("Var(z1):", var(z1), "\n")
cat("Var(z2):", var(z2), "\n")
cat("Cov(z1,z2):", cov(z1, z2), "\n")
cat("Cor(z1,z2):", cor(z1, z2), "\n\n")
}
# test for multiple p
set.seed(123)
rhos <- c(0, 0.3, 0.7, 0.9)
for (r in rhos) {
check_rho(N = 100000, rho = r)
}
set.seed(123)
# Parameters
N <- 5000
sigma <- 3
beta <- c(1, 2, 3)
num_sims <- 300
# Storage for beta_3 estimates
beta3_hat <- numeric(num_sims)
for (s in 1:num_sims) {
# Generate regressors
x1 <- rnorm(N)
x2 <- rnorm(N)
X <- cbind(1, x1, x2)
# Generate outcome
epsilon <- rnorm(N, mean = 0, sd = sigma)
y <- X %*% beta + epsilon
Y <- as.matrix(y)
# OLS estimate
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% Y
# Store beta_3 (third coefficient)
beta3_hat[s] <- beta_hat[3]
}
# Plot histogram
hist(beta3_hat,
breaks = 30,
main = expression("Histogram of " ~ hat(beta)[3]),
xlab = expression(hat(beta)[3]))
abline(v = 3, col = "red", lwd = 2)
set.seed(123)
# Parameters
N <- 5000
sigma <- 3
beta <- c(1, 2, 3)
num_sims <- 300
# Storage for beta_3 estimates
beta3_hat <- numeric(num_sims)
for (s in 1:num_sims) {
# Generate regressors
x1 <- rnorm(N)
x2 <- rnorm(N)
X <- cbind(1, x1, x2)
# Generate outcome
epsilon <- rnorm(N, mean = 0, sd = sigma)
y <- X %*% beta + epsilon
Y <- as.matrix(y)
# OLS estimate
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% Y
# Store beta_3 (third coefficient)
beta3_hat[s] <- beta_hat[3]
}
# Plot histogram
hist(beta3_hat,
breaks = 30,
main = expression("Histogram of " ~ hat(beta)[3]),
xlab = expression(hat(beta)[3]))
abline(v = 3, col = "black", lwd = 2)
set.seed(123)
# Parameters
N <- 5000
sigma <- 3
beta <- c(1, 2, 3)
num_sims <- 300
# Storage for beta_3 estimates
beta3_hat <- numeric(num_sims)
for (s in 1:num_sims) {
# Generate regressors
x1 <- rnorm(N)
x2 <- rnorm(N)
X <- cbind(1, x1, x2)
# Generate outcome
epsilon <- rnorm(N, mean = 0, sd = sigma)
y <- X %*% beta + epsilon
Y <- as.matrix(y)
# OLS estimate
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% Y
# Store beta_3 (third coefficient)
beta3_hat[s] <- beta_hat[3]
}
# Plot histogram
hist(beta3_hat,
breaks = 30,
main = expression("Histogram of " ~ hat(beta)[3]),
xlab = expression(hat(beta)[3]))
abline(v = 3, col = "red", lwd = 2)
set.seed(123)
# Parameters
N <- 5000
sigma <- 3
beta <- c(1, 2, 3)
num_sims <- 300
rho <- 0.99  # high correlation
# Storage for beta_3 estimates
beta3_hat_rho <- numeric(num_sims)
# Function to generate Z matrix with intercept
generate_Z <- function(N, rho) {
x1 <- rnorm(N)
x2 <- rnorm(N)
z1 <- rho * x1 + sqrt(1 - rho^2) * x2
z2 <- x1
Z <- cbind(1, z1, z2)
return(Z)
}
for (s in 1:num_sims) {
# Generate Z regressors
Z <- generate_Z(N, rho)
# Generate outcome
epsilon <- rnorm(N, mean = 0, sd = sigma)
y <- Z %*% beta + epsilon
# OLS estimate
beta_hat <- solve(t(Z) %*% Z) %*% t(Z) %*% y
# Store beta_3 (third coefficient)
beta3_hat_rho[s] <- beta_hat[3]
}
# Plot histogram
hist(beta3_hat_rho,
breaks = 30,
main = expression("Histogram of " ~ hat(beta)[3] ~ " with " ~ rho == 0.99),
xlab = expression(hat(beta)[3]))
abline(v = 3, col = "red", lwd = 2)
data_location <- "datasets"
#https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv
df <- read_csv("https://stat158.berkeley.edu/spring-2026/data/framing/framing.csv")
#df <- read.csv(file.path(data_location, "spotify_songs.csv"))
# run analysis
xx <- df[,c(4,12,13,14,15,16,17,18,19,20,21,22,23)]; xxx =df[,4]
spotify <- read_csv("https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv")
spotify <- spotify %>%
rename(popularity = track_popularity)
# Select numeric audio features (excluding popularity)
features <- spotify %>%
select(where(is.numeric)) %>%
select(-popularity)
# Compute correlations with popularity
correlations <- sapply(features, function(x) {
cor(spotify$popularity, x, use = "complete.obs")
})
# Put results into a data frame
results <- data.frame(
feature = names(correlations),
correlation = correlations
)
# Order by strongest positive relationship
results <- results %>%
arrange(desc(correlation))
print(results)
# Print most positively associated feature
best_feature <- results$feature[1]
cat("The feature most associated with popularity is:", best_feature)
spotify <- read_csv("https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv")
spotify <- spotify %>%
rename(popularity = track_popularity)
# Select numeric audio features (excluding popularity)
features <- spotify %>%
select(where(is.numeric)) %>%
select(-popularity)
# Compute correlations with popularity
correlations <- sapply(features, function(x) {
cor(spotify$popularity, x, use = "complete.obs")
})
# Put results into a data frame
results <- data.frame(
feature = names(correlations),
correlation = correlations
)
# Order by strongest positive relationship
results <- results %>%
arrange(desc(correlation))
print(results)
# Print most positively associated feature
best_feature <- results$feature[1]
cat("The feature most associated with popularity is:", best_feature)
library(tidyverse)
library(knitr)
spotify <- read_csv("https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv")
spotify <- spotify %>%
rename(popularity = track_popularity)
# Select numeric audio features (excluding popularity)
features <- spotify %>%
select(where(is.numeric)) %>%
select(-popularity)
# Compute correlations with popularity
correlations <- sapply(features, function(x) {
cor(spotify$popularity, x, use = "complete.obs")
})
# Put results into a data frame
results <- data.frame(
feature = names(correlations),
correlation = correlations
)
# Order by strongest positive relationship
results <- results %>%
arrange(desc(correlation))
print(results)
# Print most positively associated feature
best_feature <- results$feature[1]
cat("The feature most associated with popularity is:", best_feature)
library(tidyverse)
library(knitr)
spotify <- read.csv("https://stat151a.berkeley.edu/spring-2026/datasets/spotify/spotify_songs.csv")
spotify <- spotify %>%
rename(popularity = track_popularity)
# Select numeric audio features (excluding popularity)
features <- spotify %>%
select(where(is.numeric)) %>%
select(-popularity)
# Compute correlations with popularity
correlations <- sapply(features, function(x) {
cor(spotify$popularity, x, use = "complete.obs")
})
# Put results into a data frame
results <- data.frame(
feature = names(correlations),
correlation = correlations
)
# Order by strongest positive relationship
results <- results %>%
arrange(desc(correlation))
print(results)
# Print most positively associated feature
best_feature <- results$feature[1]
cat("The feature most associated with popularity is:", best_feature)
